python prepare_celebhqmasks.py
accelerate launch --config_file single_gpu.json train.py --data_root_path CelebaHQMaskDataset/train --mask_subfolder masks --output_dir runs/final3_photoverse_arcface_lora_rank128 --max_train_steps 40000 --train_batch_size 16 --samples_save_steps 500 --report_to wandb --use_lora --lora_rank 128 --save_samples_with_various_prompts --pretrained_photoverse_path runs/final3_photoverse_arcface_lora_rank128/photoverse_006000.pt --face_loss arcface --learning_rate 1e-5